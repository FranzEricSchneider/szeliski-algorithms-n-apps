{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2e1f7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c42f9d7cb29b206868290f1b831a70f",
     "grade": false,
     "grade_id": "cell-9e91f3f18e2f0746",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Neural Networks for Recognition - Assignment 3\n",
    "\n",
    "     Instructor: Kris Kitani                       TAs: Qichen(Lead), Paritosh, Rawal, Yan, Zen, Wen-Hsuan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61fb3c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10428476164dc2b80129a0d9c92b6f17",
     "grade": false,
     "grade_id": "cell-4ad5a6402c74aeff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4 Extract Text from Images (35 points)\n",
    "\n",
    "**Please include all the write up answers below to theory.ipynb. For the questions need code, you need to include the screenshot of code to theory.ipynb to get points.**\n",
    "\n",
    "![](figures/annotatedLetters.jpg)\n",
    "<center>Sample image with handwritten characters annotated with boxes around each character</center>\n",
    "\n",
    "Now that you have a network that can recognize handwritten letters with reasonable accuracy, you can now use it to parse text in an image. Given an image with some text on it, our goal is to have a function that returns the actual text in the image. However, since your neural network expects a a binary image with a single character, you will need to process the input image to extract each character. There are various approaches that can be done so feel free to use any strategy you like.\n",
    "\n",
    "Here we outline one possible method, another is that given in a [tutorial](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html)\n",
    "1. Process the image ([blur](http://scikit-image.org/docs/dev/auto_examples/filters/plot_denoise.html), [threshold](http://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.try_all_threshold), [opening morphology](http://scikit-image.org/docs/dev/api/skimage.morphology.html#skimage.morphology.opening), etc. (perhaps in that order)) to classify all pixels as being part of a character or background.\n",
    "2. Find connected groups of character pixels (see [skimage.measure.label](http://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label)). Place a bounding box around each connected component.\n",
    "3. Group the letters based on which line of the text they are a part of, and sort each group so that the letters are in the order they appear on the page.\n",
    "4. Take each bounding box one at a time and resize it to $32\\times 32$, classify it with your network, and report the characters in order (inserting spaces when it makes sense).\n",
    "\n",
    "Since the network you trained likely does not have perfect accuracy, you can expect there to be some errors in your final text parsing. Whichever method you choose to implement for the character detection, you should be able to place a box on most of there characters in the image. We have provided you with **01\\_list.jpg**, **02\\_letters.jpg**, **03\\_haiku.jpg** and **04\\_deep.jpg** to test your implementation on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df9d2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a4d5c702ec5cc53fa907944b5754ec3",
     "grade": false,
     "grade_id": "cell-f8a9268b86c6c4e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.1 (3 points WriteUp)\n",
    "The method outlined above is pretty simplistic, and makes several assumptions. What are two big assumptions that the sample method makes. In your writeup, include two example images where you expect the character detection to fail (either miss valid letters, or respond to non-letters).\n",
    "\n",
    "<font color=\"red\">**Please include the write up answer to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818815a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2978a50aecf562699f3bbb28ff98ccfe",
     "grade": false,
     "grade_id": "cell-31f1656690403e2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.2 (13 points Code+WriteUp)\n",
    "Find letters in the image. Given an RGB image, this function should return bounding boxes for all of the located handwritten characters in the image, as well as a binary black-and-white version of the image \\texttt{im}. Each row of the matrix should contain **[y1,x1,y2,x2]** the positions of the top-left and bottom-right corners of the box. The black and white image should be floating point, 0 to 1, with the characters in black and background in white. \n",
    "\n",
    "<font color=\"red\">**Please include the write up answer and the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eda8dbd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "960e19bfd58e3a164b94c7ebdd105f10",
     "grade": false,
     "grade_id": "cell-e7dae5ca903a2fc4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.color\n",
    "import skimage.restoration\n",
    "import skimage.io\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "# takes a color image\n",
    "# returns a list of bounding boxes and black_and_white image\n",
    "def findLetters(image, sigma=2.0):\n",
    "\n",
    "    # insert processing in here\n",
    "    # one idea estimate noise -> denoise -> greyscale -> threshold -> morphology -> label -> skip small boxes \n",
    "    # this can be 10 to 15 lines of code using skimage functions\n",
    "    # YOUR CODE HERE    \n",
    "    blurred = skimage.filters.gaussian(image, sigma=(sigma, sigma), truncate=3.0, multichannel=True)\n",
    "    gray = skimage.color.rgb2gray(blurred)\n",
    "    binary = gray > skimage.filters.threshold_otsu(gray)\n",
    "\n",
    "    # Thicken the characters up a bit depending on the image size\n",
    "    thick_scalar = int(7 * 1600 / max(binary.shape))\n",
    "    thicker = skimage.morphology.binary_erosion(\n",
    "        binary, selem=np.ones((thick_scalar, thick_scalar))\n",
    "    )\n",
    "    labelled = skimage.measure.label(thicker, background=True, connectivity=2)\n",
    "    regions = skimage.measure.regionprops(labelled)\n",
    "\n",
    "    # Decide which size of boxes to drop based on the median character size\n",
    "    area_threshold = 0.2 * np.median([region.area for region in regions])\n",
    "    bboxes = [region.bbox for region in regions if region.area > area_threshold]\n",
    "\n",
    "    return bboxes, binary.astype(float)\n",
    "\n",
    "\n",
    "# from matplotlib import pyplot\n",
    "# import skimage.draw\n",
    "# for image_path in os.listdir('images'):\n",
    "#     print(image_path)\n",
    "#     image = skimage.io.imread(os.path.join('images', image_path))\n",
    "#     bboxes, bw = findLetters(image)\n",
    "#     skimage.io.imsave(image_path.replace(\".\", \"BW.\"), (bw * 255).astype(np.uint8))\n",
    "#     pyplot.imshow(bw, interpolation='none')\n",
    "#     pyplot.show()\n",
    "#     for bbox in bboxes:\n",
    "#         rows, columns = skimage.draw.rectangle_perimeter(\n",
    "#             bbox[0:2], end=bbox[2:], shape=image.shape\n",
    "#         )\n",
    "#         image[rows, columns] = (255, 0, 0)\n",
    "#     skimage.io.imsave(image_path.replace(\".\", \"BOX.\"), image)\n",
    "#     pyplot.imshow(image)\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26e2e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "048c5ff931753cd316f9629ec8ada47d",
     "grade": false,
     "grade_id": "cell-1adb2ce6c11e2792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.3 (6 points Code+WriteUp)\n",
    "Run `findLetters()` on all of the provided sample images in **images/**. Plot all of the located boxes on top of the image to show the accuracy of your `findLetters()` function. Include all the result images in your writeup.\n",
    "\n",
    "<font color=\"red\">**Please include the write up answer and the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32d3026",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154fb23e8415aa59b81d3bcf6b615d23",
     "grade": false,
     "grade_id": "cell-5d334112fbfbd1cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "from ipynb.fs.defs.q2 import *\n",
    "\n",
    "# do not include any more libraries here!\n",
    "# no opencv, no sklearn, etc!\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "def get_row_groups(num_rows, bboxes):\n",
    "    \"\"\"\n",
    "    Get row groupings of bboxes, assuming there's at least one horizontal pixel\n",
    "    between each row. This won't handle slanted rows, which should be fine\n",
    "    since those don't appear to show up in the input images.\n",
    "    \"\"\"\n",
    "    row_groups = []\n",
    "    # TODO\n",
    "    rows = np.array(range(num_rows))\n",
    "    # TODO\n",
    "    for bbox in bboxes:\n",
    "        rows[bbox[0]:bbox[2]+1] = -1\n",
    "    # TODO\n",
    "    dividers = np.argwhere( (rows > 0)[:-1] & (rows < 0)[1:] ).T[0]\n",
    "    dividers = np.hstack((dividers, [num_rows]))\n",
    "    # TODO\n",
    "    # This is a double loop, but it's also over ~50 items and ~8, so I\n",
    "    # won't bother compressing it\n",
    "    for i in range(len(dividers) - 1):\n",
    "        row_group = []\n",
    "        for bbox in bboxes:\n",
    "            if dividers[i] < bbox[0] < dividers[i+1]:\n",
    "                row_group.append(bbox)\n",
    "        # TODO\n",
    "        row_groups.append(sorted(row_group, key=lambda x: x[1]))\n",
    "    return dividers, row_groups\n",
    "\n",
    "\n",
    "def pretty_letters(binary, row_groups):\n",
    "    \"\"\"\n",
    "    Returns a set of 32x32 images of the same layout as row_groups.\n",
    "    \"\"\"\n",
    "    image_groups = []\n",
    "    for row in row_groups:\n",
    "        image_row = []\n",
    "        for bbox in row:\n",
    "            raw = binary[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "            buffer = max(raw.shape) // 32\n",
    "            hpad = buffer + (max(raw.shape) - raw.shape[0]) // 2\n",
    "            wpad = buffer + (max(raw.shape) - raw.shape[1]) // 2\n",
    "            padded = np.pad(raw,\n",
    "                            pad_width=((hpad, hpad), (wpad, wpad)),\n",
    "                            mode='constant',\n",
    "                            constant_values=1.0)\n",
    "            im32 = skimage.transform.resize(padded, (32, 32), anti_aliasing=True)\n",
    "            image_row.append(im32.T)\n",
    "            # from matplotlib import pyplot; pyplot.imshow(im32); pyplot.show()\n",
    "        image_groups.append(image_row)\n",
    "    return image_groups\n",
    "\n",
    "\n",
    "# for img in os.listdir('images'):\n",
    "#     im1 = skimage.img_as_float(skimage.io.imread(os.path.join('images',img)))\n",
    "#     bboxes, bw = findLetters(im1)\n",
    "    \n",
    "#     plt.imshow(bw)\n",
    "#     for bbox in bboxes:\n",
    "#         minr, minc, maxr, maxc = bbox\n",
    "#         rect = matplotlib.patches.Rectangle(\n",
    "#             (minc, minr), maxc - minc, maxr - minr,\n",
    "#             fill=False, edgecolor='red', linewidth=2\n",
    "#         )\n",
    "#         plt.gca().add_patch(rect)\n",
    "#     plt.show()\n",
    "\n",
    "#     # find the rows using..RANSAC, counting, clustering, etc.\n",
    "#     # YOUR CODE HERE\n",
    "#     _, row_groups = get_row_groups(bw.shape[0], bboxes)\n",
    "\n",
    "#     # crop to the bounding boxes\n",
    "#     # note.. before you flatten, transpose the image (that's how the dataset is!)\n",
    "#     # consider doing a square crop, and even using np.pad() to get your images looking more like the dataset\n",
    "#     # YOUR CODE HERE\n",
    "#     image_groups = pretty_letters(bw, row_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7787fe1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24f6fee2d67b0fafb3077c6101731475",
     "grade": false,
     "grade_id": "cell-b6c103335a0b75db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.4 (13 points Code+WriteUp)\n",
    "Now you will load the image, find the character locations, classify each one with the network you trained in **Q3.1**, and return the text contained in the image. Be sure you try to make your detected images look like the images from the training set. Visualize them and act accordingly. \n",
    "\n",
    "<font color=\"red\">**Please include the write up answer and the screenshot of code to theory.ipynb**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b488866",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34b6e2de7dfb131a447a473b78758dd6",
     "grade": false,
     "grade_id": "cell-26374322f557beb3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_list.jpg\n",
      "T 0 D J L I S T\n",
      "I N A K E A T D D D L I S T\n",
      "I L H F C K D F E 7 H E F I R S T\n",
      "T H I N G Q N T Q D Q L I S T\n",
      "3 K 2 A L I Z E Y 0 U H A V E A L R 2 A D T\n",
      "C D M P L F T L D J T H I N G S\n",
      "4 R F W A R D Y O W R S E L F W I T H\n",
      "A N A P\n",
      "03_haiku.jpg\n",
      "H A I K U S A R E H M A S Y\n",
      "B W T S J M E T I M E S T H E Y D D W T M A K E S G M N G G M\n",
      "R B G R I G E R A M 1 Q K\n",
      "02_letters.jpg\n",
      "D B C D F F 6\n",
      "H I J K C T N\n",
      "Q P Q K S T U\n",
      "V W X Y Z\n",
      "1 Z 3 M S 6 7 Y Y J\n",
      "04_deep.jpg\n",
      "C Y F Y C K M 2 K M I X W\n",
      "Y F Y Y Y K C E D K N J T G\n",
      "C Y M Y Y Y Y T L E 2 K K I K G\n",
      "\n",
      "Length equal? False\n",
      "Accuracy: 0.1646586345381526\n"
     ]
    }
   ],
   "source": [
    "# load the weights\n",
    "# run the crops through your neural network and print them out\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.defs.q2 import *\n",
    "\n",
    "\n",
    "def classify(params, image, letters):\n",
    "    y1 = forward(image.reshape(1, 32*32), params, \"layer1\", sigmoid)\n",
    "    probs = forward(y1, params, \"output\", softmax)\n",
    "    return letters[np.argmax(probs)]\n",
    "\n",
    "\n",
    "letters = np.array([c for c in string.ascii_uppercase[:26]] + [str(n) for n in range(10)])\n",
    "params = pickle.load(open('q3_weights.pickle','rb'))\n",
    "# YOUR CODE HERE\n",
    "characters = []\n",
    "for img in os.listdir('images'):\n",
    "    print(f\"{img}\")\n",
    "    im1 = skimage.img_as_float(skimage.io.imread(os.path.join('images', img)))\n",
    "    bboxes, bw = findLetters(im1)\n",
    "    _, row_groups = get_row_groups(bw.shape[0], bboxes)\n",
    "    image_groups = pretty_letters(bw, row_groups)\n",
    "    for image_row in image_groups:\n",
    "        characters.append([classify(params, image, letters) for image in image_row])\n",
    "        print(\" \".join(characters[-1]))\n",
    "\n",
    "flattened = np.array(sum(characters, start=[]))\n",
    "correct = np.array(\n",
    "    list(\"TODOLIST1MAKEATODOLIST2CHECKOFFTHEFIRSTTHINGONTHETODOLIST\" +\n",
    "         \"3REALIZEYOUHAVEALREADYCOMPLETED2THINGS4REWARDYOURSELFWITHANAP\" +\n",
    "         \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\" +\n",
    "         \"HAIKUSAREEASYBUTSOMETIMESTHEYDONTMAKESENSEREFRIGERATOR\" +\n",
    "         \"DEEPLEARNINGDEEPERLEARNINGDEEPESTLEARNING\")\n",
    ")\n",
    "print(f\"\\nLength equal? {flattened.shape == correct.shape}\")\n",
    "print(f\"Accuracy: {np.sum(flattened[:len(correct)] == correct) / len(correct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c0378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
