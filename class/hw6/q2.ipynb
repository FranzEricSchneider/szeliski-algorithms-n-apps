{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b78209739e273da3a3bdbb15ea5cc74d",
     "grade": false,
     "grade_id": "cell-c4ab9a740c51dfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"img/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7898acafc88387d3f7ce40720bf71ef2",
     "grade": false,
     "grade_id": "cell-3c6401138ee3087d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 16720 (B)  Object Tracking in Videos - Assignment 6 - Q2\n",
    "    Instructor: Kris                          TAs: Wen-Hsuan (Lead), Zen, Yan, Rawal, Paritosh, Qichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc9f65ed0eacde8b833f81bd82b98d8d",
     "grade": false,
     "grade_id": "cell-951f7cf42448155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38804a257a8f737c4d975806d09367df",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Matthew-Bakers Inverse Compositional Alignment with Affine Matrix\n",
    "\n",
    "### Q2.1: Implementation (10 PT write-up, 20 PT implementation)\n",
    "Now we will implement the Matthew-Bakers tracker to alleviate the computational costs of the the Lucas-Kanade tracker, as it only calculates the Hessian and Jacobian once per each video. Write the function with the following function signature:\n",
    "\n",
    "```\n",
    "            M = InverseCompositionAffine(It, It1, rect)\n",
    "```\n",
    "that computes the optimal local motion represented by a $2x3$ affine transformation matrix $M$ from frame $I_t$ to frame $I_{t+1}$ that minimizes\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\mathcal{L}=\\sum_{\\mathbf{x}}[\\mathbf{T}(\\mathbf{x})-\\mathbf{I}(\\mathbf{W}(\\mathbf{x} ; \\mathbf{p}))]^{2}. \n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "The inputs are structured identically to Q1.2, but you should replace the forward alignment algorithm with the inverse compositional alignment algorithm. You may also find these materials useful: [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2002_3/baker_simon_2002_3.pdf) and [link](https://www.ri.cmu.edu/pub_files/pub3/baker_simon_2003_3/baker_simon_2003_3.pdf).\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Please include the results of the algorithm on all five videos we have provided along with your code. Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do they have those differences? At what point does the algorithm break down and why does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_M(P):\n",
    "    M = P.copy()\n",
    "    M[0, 0] += 1\n",
    "    M[1, 1] += 1\n",
    "    return M\n",
    "\n",
    "\n",
    "def inverse_warp(P):\n",
    "    # Note! These are not sequential because of the parameter order\n",
    "    p1, p3, p5, p2, p4, p6 = P.flatten()\n",
    "\n",
    "    scalar = 1 / ((1 + p1) * (1 + p4) - p2*p3)\n",
    "    return scalar * np.array([\n",
    "        -p1 - p1*p4 + p2*p3,\n",
    "        -p2,\n",
    "        -p3,\n",
    "        -p4 - p1*p4 + p2*p3,\n",
    "        -p5 - p4*p5 + p3*p6,\n",
    "        -p6 - p1*p6 + p2*p5,\n",
    "    ])\n",
    "\n",
    "\n",
    "def update_warp(P, delta_P_vector):\n",
    "    # Note! These are not sequential because of the parameter order\n",
    "    p1, p3, p5, p2, p4, p6 = P.flatten()\n",
    "\n",
    "    d1, d2, d3, d4, d5, d6 = inverse_warp(delta_P_vector)\n",
    "    n1, n2, n3, n4, n5, n6 = np.array([\n",
    "        p1 + d1 + p1*d1 + p3*d2,\n",
    "        p2 + d2 + p2*d1 + p4*d2,\n",
    "        p3 + d3 + p1*d3 + p3*d4,\n",
    "        p4 + d4 + p2*d3 + p4*d4,\n",
    "        p5 + d5 + p1*d5 + p3*d6,\n",
    "        p6 + d6 + p2*d5 + p4*d6,\n",
    "    ])\n",
    "    return np.array([\n",
    "        [n1, n3, n5],\n",
    "        [n2, n4, n6],\n",
    "    ])\n",
    "\n",
    "\n",
    "def test_update_warp(M, delta_P_vector):\n",
    "    newM = np.vstack((M, np.array([0, 0, 1])))\n",
    "    d1, d2, d3, d4, d5, d6 = delta_P_vector\n",
    "    deltaP = np.array([\n",
    "        [1 + d1, d3, d5],\n",
    "        [d2, 1 + d4, d6],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    return (newM @ np.linalg.pinv(deltaP))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0447ca55b183d49aedc2487b700c00a",
     "grade": false,
     "grade_id": "cell-75539a0c38616db4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from q1 import affine_warp, plot_impoly\n",
    "\n",
    "\n",
    "def InverseCompositionAffine(It, It1, rect, thresh=.025, maxIt=100):\n",
    "    '''\n",
    "    Q2.1: Matthew-Bakers Inverse Compositional Alignment with Affine Matrix\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        M: Affine matrix (2x3)\n",
    "    '''\n",
    "    \n",
    "    # Set thresholds (you probably want to play around with the values)\n",
    "    P = np.zeros((2,3))\n",
    "    threshold = thresh\n",
    "    maxIters = maxIt\n",
    "    x1, y1, x2, y2 = rect\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    M = P.copy()\n",
    "    np.fill_diagonal(M, 1)\n",
    "    \n",
    "    # Pre-create splines for both images, for speed reasons. Taking\n",
    "    # the full-image spline is expensive\n",
    "    # Importantly, although we are interpreting x as horizontal and y as vertical,\n",
    "    # RectBivariateSpline does not. Hence when given image we set x=shape[0] and\n",
    "    # y=shape[1]\n",
    "    template_spline = RectBivariateSpline(x=np.array(range(It.shape[0])),\n",
    "                                          y=np.array(range(It.shape[1])),\n",
    "                                          z=It)\n",
    "    image_spline = RectBivariateSpline(x=np.array(range(It1.shape[0])),\n",
    "                                       y=np.array(range(It1.shape[1])),\n",
    "                                       z=It1)\n",
    "\n",
    "    # Get the template patch and gradients once\n",
    "    template, template_Ix, template_Iy, template_x, template_y = \\\n",
    "        affine_warp(template_spline, M=M, rect=rect, image=It, buffer=0.1)\n",
    "        # affine_warp(template_spline, M=make_M(P), rect=rect, image=It)\n",
    "    template_Ix = template_Ix.flatten()\n",
    "    template_Iy = template_Iy.flatten()\n",
    "\n",
    "    # Optional visualization\n",
    "    # plt.imshow(template); plt.title(\"Template\"); plt.show()\n",
    "    # plt.imshow(template_Ix.reshape(template.shape)); plt.title(\"template_Ix\"); plt.show()\n",
    "    # plt.imshow(template_Ix.reshape(template.shape)); plt.title(\"template_Ix\"); plt.show()\n",
    "\n",
    "    # Get the steepest descent images \n",
    "    grad_T_dWdp = np.vstack((template_Ix * template_x,\n",
    "                             template_Iy * template_x,\n",
    "                             template_Ix * template_y,\n",
    "                             template_Iy * template_y,\n",
    "                             template_Ix,\n",
    "                             template_Iy)).T\n",
    "    \n",
    "    # Get the Hessian (note that the transpose order is opposite of\n",
    "    # the paper, that's because grad_T_dWdp was naturally a big row,\n",
    "    # and so big row @ big column = the 6x6 we want). Doing pinv for\n",
    "    # robustness\n",
    "    hessian = grad_T_dWdp.T @ grad_T_dWdp\n",
    "    inv_hessian = np.linalg.pinv(hessian)\n",
    "\n",
    "    for i in range(maxIters):\n",
    "        # Get warps with the new M\n",
    "        warped_patch, _, _, _, _ = \\\n",
    "            affine_warp(image_spline, M, rect, It1, buffer=0.1, compute_gradients=False)\n",
    "            # affine_warp(image_spline, make_M(P), rect, It1, compute_gradients=False)\n",
    "        \n",
    "        # Optional visualization\n",
    "        # if i % 10 == 0:\n",
    "        #     print(i, P, M)\n",
    "        #     plt.imshow(warped_patch); plt.title(\"warped_patch\"); plt.show()\n",
    "\n",
    "        # Get the I(W(x, p)) - T(x) term\n",
    "        error = warped_patch.flatten() - template.flatten()\n",
    "        \n",
    "        # Do the sum of J*b. J is (6, N) so when we sum we get shape (6,)\n",
    "        sum_vector = grad_T_dWdp.T @ error\n",
    "        # Then compute delta P using equation 19\n",
    "        delta_P_vector = inv_hessian @ sum_vector\n",
    "\n",
    "        # Update the warp parameters\n",
    "        # P = update_warp(P, delta_P_vector)\n",
    "        M = test_update_warp(M, delta_P_vector)\n",
    "\n",
    "        if np.linalg.norm(delta_P_vector) < threshold:\n",
    "            break\n",
    "\n",
    "    # Visualization plots\n",
    "    # plot_impoly(It1, rect, make_M(P))\n",
    "    # TEMP, _, _, _, _ = affine_warp(image_spline, make_M(P), rect, It1); plt.imshow(TEMP); plt.show()\n",
    "    # return make_M(P)\n",
    "    # plot_impoly(It1, rect, M)\n",
    "    # TEMP, _, _, _, _ = affine_warp(image_spline, M, rect, It1); plt.imshow(TEMP); plt.show()\n",
    "    return M\n",
    "\n",
    "\n",
    "# # Explore for a shifted image\n",
    "# data_name = \"car2\"\n",
    "# data = np.load('./data/%s.npy' % data_name)\n",
    "# initial = np.array([59, 116, 145, 151])\n",
    "# numFrames = data.shape[2]\n",
    "# It = data[:,:,0]\n",
    "# def translate_M(p0, p1):\n",
    "#     return np.array([[1, 0, p1], [0, 1, p0]])\n",
    "\n",
    "# # MUCH MORE SENSITIVE THAN THE TRANSLATION VERSION\n",
    "# # Construct a modified It as It1 for different positive offsets\n",
    "# for p0, p1 in ((1, 1), (2, 5), (7, 1), (1, 5)):\n",
    "#     if p0 == 0 or p1 == 0:\n",
    "#         It1 = It.copy()\n",
    "#     else:\n",
    "#         It1 = np.zeros(It.shape, dtype=np.uint8)\n",
    "#         It1[p0:, p1:] = It[:-p0, :-p1]\n",
    "#     # THEN call image alignment on it\n",
    "#     calc_M = InverseCompositionAffine(It, It1, initial)\n",
    "#     print(f\"{calc_M} is close to \\n{translate_M(p0, p1)}? {np.allclose(calc_M, translate_M(p0, p1))}\")\n",
    "# # Again for negatives?\n",
    "# for p0, p1 in ((-1, -1), (-2, -5), (-7, -1), (-1, -5)):\n",
    "#     It1 = np.zeros(It.shape, dtype=np.uint8)\n",
    "#     It1[:p0, :p1] = It[-p0:, -p1:]\n",
    "#     # THEN call image alignment on it\n",
    "#     calc_M = InverseCompositionAffine(It, It1, initial)\n",
    "#     print(f\"{calc_M} is close to \\n{translate_M(p0, p1)}? {np.allclose(calc_M, translate_M(p0, p1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 \n",
      "car2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 "
     ]
    }
   ],
   "source": [
    "# Test your algorithm and visualize results!\n",
    "\n",
    "# Load data\n",
    "for data_name in [\"car1\", \"car2\", \"landing\", \"race\", \"ballet\"]:\n",
    "    print(f\"\\n{data_name}\")\n",
    "    data = np.load('./data/%s.npy' % data_name)\n",
    "\n",
    "    # obtain the initial rect with format (x1, y1, x2, y2)\n",
    "    if data_name == 'car1':\n",
    "        initial = np.array([170, 130, 290, 250])\n",
    "    elif data_name == 'car2':\n",
    "        initial = np.array([59, 116, 145, 151])\n",
    "    elif data_name == 'landing':\n",
    "        initial = np.array([440, 80, 560, 140])\n",
    "    elif data_name == 'race':\n",
    "        initial = np.array([170, 270, 300, 370])\n",
    "    elif data_name == 'ballet':\n",
    "        initial = np.array([700, 210, 775, 300])\n",
    "    else:\n",
    "        assert False, 'the data name must be one of (car1, car2, landing, race, ballet)'\n",
    "\n",
    "    numFrames = data.shape[2]\n",
    "    w = initial[2] - initial[0]\n",
    "    h = initial[3] - initial[1]\n",
    "\n",
    "    # loop over frames\n",
    "    rects = []\n",
    "    rects.append(initial)\n",
    "\n",
    "    for i in range(numFrames-1):\n",
    "\n",
    "        It = data[:,:,i]\n",
    "        It1 = data[:,:,i+1]\n",
    "        rect = rects[i]\n",
    "\n",
    "        # run algorithm and collect rects\n",
    "        M = InverseCompositionAffine(It, It1, rect)\n",
    "        corners = np.array([[rect[0], rect[1], 1], \n",
    "                            [rect[2], rect[3], 1]]).transpose()\n",
    "        newRect = np.matmul(M, corners).transpose().reshape((4, ))\n",
    "        rects.append(newRect)\n",
    "\n",
    "        # Visualize\n",
    "        fig = plt.figure(1)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.add_patch(patches.Rectangle((rect[0], rect[1]), rect[2]-rect[0]+1, rect[3]-rect[1]+1, linewidth=2, edgecolor='red', fill=False))\n",
    "        plt.imshow(It1, cmap='gray')\n",
    "        # plt.show()\n",
    "        # ax.clear()\n",
    "        plt.savefig(f\"./vis/{data_name}_{i}.png\")\n",
    "        plt.close(fig)\n",
    "        print(f\"{i} \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e51668c14367108d67297049924981",
     "grade": true,
     "grade_id": "q2_1",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For some transparency: we evaluate on multiple frames in a given video starting from the first frame.\n",
    "# We then compare against the reference implementation and calculate the sum of all differences.\n",
    "# You should not need to tune anything for the autograding. We pass in the same hyperparameters for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d90151aa6f37d11f3d3c4c61d5eff9",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.2: Comparing Your Algorithms (write-up only, 10 PT)\n",
    "Compare the results of the Matthew-Bakers Tracker with the previous algorithms you have implemented. How do your algorithms perform on each video? What are the differences of the three algorithms in terms of performance and why do we have those differences?  At what point does the algorithm break down and why does this happen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
